{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f732053",
   "metadata": {},
   "source": [
    "ü§ñ Desenvolvimento de Modelos Preditivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c61990",
   "metadata": {},
   "source": [
    "üîç Importa√ß√£o de bibliotecas especializadas para an√°lise de dados agr√≠colas\n",
    "\n",
    "Nesta c√©lula, s√£o importadas bibliotecas essenciais para an√°lise de dados e pr√©-processamento e modelagem (sklearn). Essas ferramentas fornecem funcionalidades fundamentais para manipula√ß√£o de datasets, transforma√ß√£o de vari√°veis e constru√ß√£o de modelos preditivos eficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Importa√ß√£o de bibliotecas especializadas para an√°lise de dados agr√≠colas\n",
    "\n",
    "# ------------------------------\n",
    "# üìä Manipula√ß√£o e Visualiza√ß√£o\n",
    "# ------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# ------------------------------\n",
    "# üîÑ Pr√©-processamento\n",
    "# ------------------------------\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# ------------------------------\n",
    "# ü§ñ Modelagem (Classificadores)\n",
    "# ------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# ------------------------------\n",
    "# üß™ Avalia√ß√£o de Desempenho\n",
    "# ------------------------------\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# ‚öôÔ∏è Utilit√°rios\n",
    "# ------------------------------\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a8f42",
   "metadata": {},
   "source": [
    "üìÇ Defini√ß√£o do caminho de acesso aos dados da lavoura\n",
    "\n",
    "Aqui, o caminho do arquivo .csv contendo os dados agr√≠colas √© definido em uma vari√°vel. Essa pr√°tica torna o c√≥digo mais organizado e permite reutilizar facilmente o caminho do arquivo ao longo do notebook, facilitando ajustes e reaproveitamento do script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìÇ Defini√ß√£o do caminho de acesso aos dados da lavoura\n",
    "\n",
    "csv_path = \"Atividade_Cap_14_produtos_agricolas.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0f9ff",
   "metadata": {},
   "source": [
    "üì• Carregamento do dataset para estrutura tabular do pandas\n",
    "\n",
    "Esta etapa carrega os dados do arquivo CSV para um DataFrame, a estrutura de dados mais comum do pandas. Isso permite o uso de diversas ferramentas para explora√ß√£o, limpeza e an√°lise estat√≠stica dos dados referentes a culturas agr√≠colas como milho e cana-de-a√ß√∫car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac98697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üì• Carregamento do dataset para estrutura tabular do pandas\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e8aab",
   "metadata": {},
   "source": [
    "üîé Inspe√ß√£o inicial do dataset para compreens√£o de vari√°veis e formato\n",
    "\n",
    "Visualizar as primeiras linhas do DataFrame com df.head() serve como um ponto de partida para compreender a estrutura do dataset, verificar nomes de colunas, tipos de vari√°veis (como nitrog√™nio, pH, umidade etc.) e identificar poss√≠veis anomalias logo no in√≠cio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0176462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üîé Inspe√ß√£o inicial do dataset para compreens√£o de vari√°veis e formato\n",
    "\n",
    "# 4.1) Exibir primeiras linhas do dataset\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686cec5",
   "metadata": {},
   "source": [
    "üßæ Diagn√≥stico estrutural do DataFrame e tipagem dos dados com df.info()\n",
    "\n",
    "Utiliza-se o m√©todo df.info() para obter um resumo t√©cnico da estrutura do dataset. Essa fun√ß√£o retorna:\n",
    "\n",
    "- N√∫mero total de entradas (linhas);\n",
    "- N√∫mero e o nome das colunas;\n",
    "- N√∫mero de valores n√£o nulos em cada coluna;\n",
    "- Tipo de dado de cada coluna (int64, float64, object, etc.);\n",
    "- Uso aproximado de mem√≥ria.\n",
    "\n",
    "Essa an√°lise √© essencial para validar se:\n",
    "\n",
    "Todas as colunas foram corretamente interpretadas pelo pandas (ex: float ao inv√©s de object), se existem colunas com valores ausentes (non-null < total) e se h√° necessidade de otimizar tipos de dados para uso eficiente de mem√≥ria, principalmente em grandes volumes de dados. Essa inspe√ß√£o ajuda a antecipar problemas e tomar decis√µes sobre pr√©-processamento antes da an√°lise ou modelagem.\n",
    "\n",
    "üîç Complementos √∫teis (comentados):\n",
    "Al√©m do df.info(), o c√≥digo menciona outras fun√ß√µes que aprofundam a compreens√£o sobre a estrutura do conjunto de dados.\n",
    "\n",
    "Essas informa√ß√µes ajudam a entender melhor como os dados est√£o organizados e se h√° problemas que precisam ser corrigidos, como colunas com dados ausentes ou tipos de dados incorretos. Por exemplo, √© importante garantir que colunas com n√∫meros estejam em tipos num√©ricos adequados (int ou float), e que colunas com nomes de culturas estejam como object (texto). Com esse diagn√≥stico inicial, podemos planejar os pr√≥ximos passos da an√°lise com mais seguran√ßa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d14079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üßæ Diagn√≥stico estrutural do DataFrame e tipagem dos dados com df.info() e Complementos √∫teis (comentados):\n",
    "\n",
    "df.info()\n",
    "\n",
    "#df.shape ‚Üí Retorna (2200, 8), indicando que o dataset possui 2200 amostras (linhas) e 8 atributos (colunas).\n",
    "\n",
    "#df.columns ‚Üí Lista os nomes das colunas, revelando que os atributos medem nutrientes (N, P, K), vari√°veis ambientais (temperatura, umidade, pH, precipita√ß√£o) e a vari√°vel alvo \n",
    "# label (tipo de cultura agr√≠cola).\n",
    "\n",
    "#df.dtypes ‚Üí Retorna os tipos de dados:\n",
    "#int64 para nutrientes (N, P, K)\n",
    "#float64 para vari√°veis cont√≠nuas (temperature, humidity, ph, rainfall)\n",
    "#object para a label, pois √© uma vari√°vel categ√≥rica (string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2f563",
   "metadata": {},
   "source": [
    "üö® Detec√ß√£o de dados faltantes para avalia√ß√£o da necessidade de imputa√ß√£o\n",
    "\n",
    "Esta etapa verifica a presen√ßa de valores nulos no dataset utilizando df.isnull().sum(). Embora a fun√ß√£o df.info() tamb√©m identifique dados faltantes, sua visualiza√ß√£o pode ser menos intuitiva. A exist√™ncia de valores ausentes pode prejudicar tanto a an√°lise explorat√≥ria quanto o desempenho dos modelos preditivos. Por isso, √© fundamental decidir uma estrat√©gia adequada, como imputa√ß√£o, exclus√£o de linhas ou colunas, ou o uso de modelos que suportem dados nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üö® Detec√ß√£o de dados faltantes para avaliar necessidade de imputa√ß√£o\n",
    "\n",
    "print(df.isnull().sum()) # nao existe nenhum nulo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a849f069",
   "metadata": {},
   "source": [
    "üîÅ Detec√ß√£o de entradas redundantes no dataset\n",
    "\n",
    "Esta c√©lula tem como objetivo identificar registros duplicados, ou seja, linhas que aparecem mais de uma vez com os mesmos valores em todas as colunas. Isso √© feito por meio do m√©todo df.duplicated(), que retorna uma s√©rie booleana indicando True para as linhas duplicadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üîÅ Detec√ß√£o de entradas redundantes no dataset\n",
    "duplicates= df.duplicated().sum()\n",
    "print(f\"Total de duplicados: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff394ff0",
   "metadata": {},
   "source": [
    "üßπ Limpeza de dados redundantes\n",
    "\n",
    "O m√©todo drop_duplicates() remove todas as entradas repetidas, mantendo apenas a primeira ocorr√™ncia. O argumento inplace=True faz com que a modifica√ß√£o seja feita diretamente no DataFrame original (df), sem a necessidade de reatribui√ß√£o, remover duplicatas √© uma etapa importante na prepara√ß√£o dos dados, pois ajuda a garantir a qualidade, consist√™ncia e confiabilidade das an√°lises e dos modelos de aprendizado de m√°quina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üßπ Limpeza de dados redundantes (exemplo)\n",
    "#df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f13317b",
   "metadata": {},
   "source": [
    "üìä Detec√ß√£o e tratamento de valores extremos com IQR \n",
    "\n",
    "Esta c√©lula tem o objetivo de identificar e tratar outliers (valores fora do padr√£o esperado) na coluna 'temperature', utilizando o m√©todo do Intervalo Interquartil (IQR), tratar outliers √© essencial para evitar distor√ß√µes em modelos de regress√£o, classificadores e estat√≠sticas descritivas, especialmente em modelos sens√≠veis a valores extremos, como KNN e regress√£o linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä Detec√ß√£o e tratamento de valores extremos com IQR (exemplo)\n",
    "\n",
    "## Identificando os outliers usando o m√©todo do Intervalo Interquartil (IQR)\n",
    "#Q1 = df['temperature'].quantile(0.25)  # Primeiro quartil\n",
    "#Q3 = df['temperature'].quantile(0.75)  # Terceiro quartil\n",
    "#IQR = Q3 - Q1  # Intervalo interquartil\n",
    "\n",
    "## Definir limites para outliers\n",
    "#outlier_lower = Q1 - 1.5 * IQR  # Limite inferior\n",
    "#outlier_upper = Q3 + 1.5 * IQR  # Limite superior\n",
    "\n",
    "## Calcular a mediana da temperatura\n",
    "#median_temperature = df['temperature'].median()\n",
    "\n",
    "## Substituir os outliers pela mediana\n",
    "#df['temperature'] = df['temperature'].apply(lambda x: median_temperature if x < outlier_lower or x > outlier_upper else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25ec5c",
   "metadata": {},
   "source": [
    "üìä Estat√≠sticas descritivas para an√°lise quantitativa preliminar\n",
    "\n",
    "Com df.describe(), obtemos medidas estat√≠sticas como m√©dia, mediana, desvio padr√£o e quartis para vari√°veis num√©ricas. Isso fornece uma no√ß√£o do comportamento e da dispers√£o dos dados, ajudando a identificar outliers e padr√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a117daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä Estat√≠sticas descritivas para an√°lise quantitativa preliminar\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa07d1",
   "metadata": {},
   "source": [
    "üéØ Quantifica√ß√£o das classes da vari√°vel alvo\n",
    "\n",
    "A fun√ß√£o df['label'].value_counts() permite entender quantas amostras existem para cada cultura agr√≠cola no dataset. Isso ajuda a verificar se as classes est√£o balanceadas ou se h√° desbalanceamento, o que afeta diretamente o desempenho de modelos classificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üéØ Quantifica√ß√£o das classes da vari√°vel alvo\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0948779",
   "metadata": {},
   "source": [
    "üéØ Separando os dados em vari√°veis preditoras e vari√°vel target \n",
    "\n",
    "Nesta etapa, fazemos a divis√£o dos dados em:\n",
    "\n",
    "X: vari√°veis preditoras (features), que cont√™m as informa√ß√µes do solo e clima ‚Äî como nitrog√™nio (N), f√≥sforo (P), pot√°ssio (K), temperatura, umidade, pH e precipita√ß√£o. Essas ser√£o as entradas para os modelos.\n",
    "y: vari√°vel target (r√≥tulo), que indica o tipo de cultura agr√≠cola (label) que queremos prever.\n",
    "\n",
    "Essa separa√ß√£o √© fundamental para o treinamento dos modelos de machine learning, pois permite que eles aprendam a rela√ß√£o entre as condi√ß√µes do ambiente (X) e o tipo de cultura ideal (y). Assim, podemos avaliar a capacidade preditiva dos algoritmos para recomendar o produto agr√≠cola adequado √†s condi√ß√µes fornecidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üéØ Separando os dados em vari√°veis preditoras e vari√°vel target \n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b420399",
   "metadata": {},
   "source": [
    "üéØ Convers√£o da vari√°vel alvo categ√≥rica para formato num√©rico\n",
    "\n",
    "Algoritmos de machine learning geralmente exigem que a vari√°vel alvo (label) esteja em formato num√©rico. Esta etapa utiliza o LabelEncoder, e em casos mais complexos o One-Hot Enconding (como exemplificado abaixo),  para transformar categorias textuais (como o tipo de cultura) em n√∫meros, preservando a associa√ß√£o entre as classes e preparando os dados para o treinamento supervisionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üéØ Convers√£o da vari√°vel alvo categ√≥rica para formato num√©rico\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "#Lista de colunas categ√≥ricas e aplica√ß√£o de One-Hot Encoding caso fosse necess√°rio\n",
    "categorical_cols = []\n",
    "\n",
    "#Exemplo de aplica√ß√£o de One-Hot Encoding\n",
    "if categorical_cols:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    X_encoded = pd.DataFrame(\n",
    "        ohe.fit_transform(X[categorical_cols]).toarray(),\n",
    "        index=X.index\n",
    "    )\n",
    "    X_encoded = X_encoded.add_prefix('OHE_')\n",
    "\n",
    "    #Remover colunas categ√≥ricas do DataFrame original (exemplo)\n",
    "    X = X.drop(categorical_cols, axis=1)\n",
    "\n",
    "    #Concatenar o DataFrame original com o DataFrame codificado (exemplo)\n",
    "    X  = pd.concat([X, X_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c25cb2",
   "metadata": {},
   "source": [
    "‚úÇÔ∏è Separa√ß√£o dos dados em conjuntos de treino e teste com estratifica√ß√£o\n",
    "\n",
    "Aqui os dados s√£o divididos em conjuntos de treinamento e teste com base em uma propor√ß√£o definida (80/20). O par√¢metro stratify=y garante que a distribui√ß√£o das classes da vari√°vel alvo seja preservada em ambas as amostras, o que √© fundamental para garantir avalia√ß√µes mais realistas e imparciais dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#‚úÇÔ∏è Separa√ß√£o dos dados em conjuntos de treino e teste com estratifica√ß√£o\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc, test_size=0.2, random_state=42, stratify=y_enc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182350c8",
   "metadata": {},
   "source": [
    "üìè Escalonamento das vari√°veis num√©ricas para melhorar desempenho dos modelos\n",
    "\n",
    "A normaliza√ß√£o dos dados, feita com MinMaxScaler, ajusta as vari√°veis para uma mesma escala (geralmente de 0 a 1). Isso √© crucial para algoritmos que s√£o sens√≠veis √† magnitude dos dados, como KNN e SVM, garantindo que nenhuma vari√°vel domine a modelagem apenas por ter valores maiores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìè Escalonamento das vari√°veis num√©ricas para melhorar desempenho dos modelos\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd13865a",
   "metadata": {},
   "source": [
    "üîÑ Configurar valida√ß√£o cruzada estratificada com StratifiedKFold \n",
    "\n",
    "Aqui, utilizamos o StratifiedKFold para criar 5 divis√µes (folds) dos dados que preservam a propor√ß√£o original das classes em cada parte. Configuramos o embaralhamento dos dados (shuffle=True) para garantir aleatoriedade na divis√£o e definimos uma semente fixa (random_state=42) para resultados reproduz√≠veis, essa configura√ß√£o assegura que o modelo seja avaliado de forma equilibrada e consistente em diferentes subconjuntos do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üîÑ Configurar valida√ß√£o cruzada estratificada com StratifiedKFold \n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46a195",
   "metadata": {},
   "source": [
    "‚öôÔ∏è Instancia√ß√£o de modelos de aprendizado supervisionado para classifica√ß√£o\n",
    "\n",
    "Nesta c√©lula, criamos uma lista de 20 modelos de machine learning para classifica√ß√£o, com diferentes algoritmos e hiperpar√¢metros aleat√≥rios. Os modelos incluem Regress√£o Log√≠stica, √Årvore de Decis√£o, Random Forest, Gradient Boosting, SVM, KNN e Naive Bayes.\n",
    "\n",
    "Para garantir diversidade, cada modelo recebe um nome √∫nico baseado em seus hiperpar√¢metros, evitando duplicatas. Essa variedade permite testar diferentes configura√ß√µes e comparar seu desempenho na tarefa de prever a cultura agr√≠cola a partir de caracter√≠sticas do solo e clima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69049ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#‚öôÔ∏è Instancia√ß√£o de modelos de aprendizado supervisionado para classifica√ß√£o\n",
    "\n",
    "# Fun√ß√µes auxiliares para gerar varia√ß√µes aleat√≥rias\n",
    "random_state = lambda: random.randint(1, 100)\n",
    "n_estimators = lambda: random.choice([50, 100, 150, 200])\n",
    "k_neighbors = lambda: random.choice([3, 5, 7, 10, 15])\n",
    "max_depth = lambda: random.choice([None, 3, 5, 10])\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "hidden_layer_sizes = lambda: random.choice([(50,), (100,), (50, 50), (100, 50)])\n",
    "\n",
    "modelos = []\n",
    "nomes_gerados = set()\n",
    "\n",
    "while len(modelos) < 20:\n",
    "    modelo_tipo = random.choice([\n",
    "        'lr', 'dt', 'rf', 'gb', 'svm', 'knn', 'nb',\n",
    "        'et', 'ada', 'lda', 'qda', 'mlp', 'bag', 'cal'\n",
    "    ])\n",
    "    \n",
    "    if modelo_tipo == 'lr':\n",
    "        nome = f'LogReg {random_state()}'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = LogisticRegression(max_iter=1000, random_state=random_state())\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "    \n",
    "    elif modelo_tipo == 'dt':\n",
    "        depth = max_depth()\n",
    "        nome = f'DecTree d{depth}'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = DecisionTreeClassifier(max_depth=depth, random_state=random_state())\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "    \n",
    "    elif modelo_tipo == 'rf':\n",
    "        n = n_estimators()\n",
    "        nome = f'RandForest {n}'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = RandomForestClassifier(n_estimators=n, random_state=random_state())\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "    \n",
    "    elif modelo_tipo == 'gb':\n",
    "        n = n_estimators()\n",
    "        nome = f'GradBoost {n}'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = GradientBoostingClassifier(n_estimators=n, random_state=random_state())\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "\n",
    "    elif modelo_tipo == 'et':\n",
    "        n = n_estimators()\n",
    "        nome = f'ExtraTrees {n}'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = ExtraTreesClassifier(n_estimators=n, random_state=random_state())\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "\n",
    "    elif modelo_tipo == 'ada':\n",
    "        n = n_estimators()\n",
    "        nome = f'AdaBoost {n}'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = AdaBoostClassifier(n_estimators=n, random_state=random_state())\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "    \n",
    "    elif modelo_tipo == 'svm':\n",
    "        kernel = random.choice(kernels)\n",
    "        nome = f'SVM {kernel}'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = SVC(kernel=kernel, probability=True, random_state=random_state())\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "\n",
    "    elif modelo_tipo == 'knn':\n",
    "        k = k_neighbors()\n",
    "        nome = f'KNN {k}'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = KNeighborsClassifier(n_neighbors=k)\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "\n",
    "    elif modelo_tipo == 'nb':\n",
    "        nome = f'Naive Bayes {random_state()}'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = GaussianNB()\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "\n",
    "    elif modelo_tipo == 'lda':\n",
    "        nome = 'LDA'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = LinearDiscriminantAnalysis()\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "\n",
    "    elif modelo_tipo == 'qda':\n",
    "        nome = 'QDA'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = QuadraticDiscriminantAnalysis()\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "\n",
    "    elif modelo_tipo == 'mlp':\n",
    "        hls = hidden_layer_sizes()\n",
    "        nome = f'MLP {hls}'\n",
    "        if nome not in nomes_gerados:\n",
    "            modelo = MLPClassifier(hidden_layer_sizes=hls, max_iter=1000, random_state=random_state())\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "\n",
    "    elif modelo_tipo == 'bag':\n",
    "        base_depth = max_depth()\n",
    "        nome = f'Bagging DT d{base_depth}'\n",
    "        if nome not in nomes_gerados:\n",
    "            base_est = DecisionTreeClassifier(max_depth=base_depth, random_state=random_state())\n",
    "            modelo = BaggingClassifier(estimator=base_est, n_estimators=n_estimators(), random_state=random_state())\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)\n",
    "\n",
    "    elif modelo_tipo == 'cal':\n",
    "        # CalibratedClassifierCV precisa de base, usar SVM linear\n",
    "        nome = 'Calibrated SVM linear'\n",
    "        if nome not in nomes_gerados:\n",
    "            base_svm = SVC(kernel='linear', probability=False, random_state=random_state())\n",
    "            modelo = CalibratedClassifierCV(base_svm)\n",
    "            modelos.append((nome, modelo))\n",
    "            nomes_gerados.add(nome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b56bece",
   "metadata": {},
   "source": [
    "üìä Treinamento dos modelos, valida√ß√£o cruzada e avalia√ß√£o preditiva\n",
    "\n",
    "Nesta c√©lula, executa-se o ciclo completo de aprendizado de m√°quina para cada modelo instanciado: \n",
    "\n",
    "- ‚è±Ô∏è *Treinamento* com os dados de treino (`X_train`, `y_train`);\n",
    "- üîÅ *Predi√ß√£o* e avalia√ß√£o no conjunto de teste (`X_test`, `y_test`);\n",
    "- üìà *Coleta de m√©tricas preditivas* como Acur√°cia, Precis√£o, Recall, F1-Score e ROC AUC;\n",
    "- ‚è≥ *Registro do tempo de treinamento* de cada modelo;\n",
    "- üì¶ Armazenamento dos modelos treinados e de suas predi√ß√µes para uso posterior.\n",
    "\n",
    "Essa abordagem permite comparar o desempenho e a efici√™ncia de m√∫ltiplos algoritmos sob as mesmas condi√ß√µes experimentais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä Treinamento dos modelos, valida√ß√£o cruzada e avalia√ß√£o preditiva\n",
    "\n",
    "\n",
    "# Avalia√ß√£o dos modelos\n",
    "resultados = []\n",
    "tempos = []\n",
    "parametros = []\n",
    "modelos_treinados = {}\n",
    "y_preds = {}\n",
    "resultados = []\n",
    "\n",
    "for nome, modelo in modelos:\n",
    "    print(f\"Treinando: {nome}\")\n",
    "    inicio = time.time()\n",
    "\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    fim = time.time()\n",
    "    duracao = fim - inicio\n",
    "\n",
    "    try:\n",
    "        y_proba = modelo.predict_proba(X_test)\n",
    "        if len(set(y)) == 2:\n",
    "            auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "        else:\n",
    "            auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "    except:\n",
    "        auc = None\n",
    "\n",
    "    resultados.append({\n",
    "        'Modelo': nome,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "        'F1 Score': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'ROC AUC': auc\n",
    "    })\n",
    "\n",
    "    modelos_treinados[nome] = modelo\n",
    "    y_preds[nome] = y_pred\n",
    "    tempos.append({'Modelo': nome, 'Tempo Treinamento (s)': round(duracao, 3)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bdae66",
   "metadata": {},
   "source": [
    "üìà Organiza√ß√£o e exibi√ß√£o dos resultados de desempenho dos modelos\n",
    "\n",
    "Esta c√©lula organiza os resultados obtidos durante a avalia√ß√£o dos modelos em um DataFrame, ordenando-os pela m√©trica F1 Score para destacar os modelos com melhor desempenho geral. Al√©m disso, registra o tempo de treinamento de cada modelo em um segundo DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2f3f5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#üìà Organiza√ß√£o e exibi√ß√£o dos resultados de desempenho dos modelos\n",
    "\n",
    "atual_resultados = pd.DataFrame(resultados).sort_values(by='F1 Score', ascending=False)\n",
    "df_resultados = atual_resultados\n",
    "df_tempos = pd.DataFrame(tempos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ec463",
   "metadata": {},
   "source": [
    "#üìã Compara√ß√£o visual entre modelos com base em m√©tricas de classifica√ß√£o\n",
    "\n",
    "Esta c√©lula define e executa a fun√ß√£o `exibir_metricas`, respons√°vel por gerar visualiza√ß√µes comparativas entre os modelos de machine learning avaliados. As visualiza√ß√µes incluem:\n",
    "\n",
    "- *Gr√°fico de barras do F1 Score*: mostra quais modelos obtiveram melhor desempenho equilibrado entre precis√£o e recall.\n",
    "- *Mapa de calor das m√©tricas*: apresenta uma vis√£o geral das principais m√©tricas (Accuracy, Precision, Recall, F1 Score e ROC AUC) para todos os modelos.\n",
    "- *Gr√°fico de tempo de treinamento*: compara a efici√™ncia temporal de cada modelo, indicando o tempo necess√°rio para treinar cada um deles.\n",
    "\n",
    "Essas visualiza√ß√µes ajudam a identificar os modelos mais eficazes e eficientes para o conjunto de dados agr√≠cola analisado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28cdb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìã Compara√ß√£o visual entre modelos com base em m√©tricas de classifica√ß√£o\n",
    "\n",
    "def exibir_metricas(df_resultados, df_tempos):\n",
    "    # Barplot - F1 Score\n",
    "    plt.figure(figsize=(12, max(6, len(df_resultados) * 0.4)))\n",
    "    sns.barplot(data=df_resultados, x='F1 Score', y='Modelo', hue='Modelo', palette='viridis', legend=False)\n",
    "    plt.title('F1 Score por Modelo (Todos)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Heatmap - Todas as m√©tricas\n",
    "    plt.figure(figsize=(14, max(6, len(df_resultados) * 0.4)))\n",
    "    heatmap_data = df_resultados.drop(columns='Modelo').set_index(df_resultados['Modelo']).astype(float)\n",
    "    sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt='.2f')\n",
    "    plt.title('üìä Heatmap Desempenho dos Modelos (Todos)')\n",
    "    plt.rcParams['font.family'] = 'Segoe UI Emoji'\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Tempo de treinamento\n",
    "    plt.figure(figsize=(12, max(6, len(df_tempos) * 0.4)))\n",
    "    sns.barplot(data=df_tempos, x='Tempo Treinamento (s)', y='Modelo', hue='Modelo', palette='magma', legend=False)\n",
    "    plt.title('‚è±Ô∏è Tempo de Treinamento por Modelo (Todos)')\n",
    "    plt.rcParams['font.family'] = 'Segoe UI Emoji'\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "exibir_metricas(df_resultados, df_tempos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc4a98",
   "metadata": {},
   "source": [
    "üèÜ Verifica√ß√£o e atualiza√ß√£o dos 5 melhores modelos\n",
    "\n",
    "Esta c√©lula mant√©m um hist√≥rico dos 5 modelos com melhor desempenho com base na m√©trica F1 Score. Se j√° existir um arquivo melhores_modelos.csv, ele √© carregado e combinado com os resultados atuais. A lista combinada √© ent√£o ordenada, duplicatas s√£o removidas e os 5 melhores modelos √∫nicos s√£o selecionados. Por fim, a nova lista √© salva no mesmo arquivo CSV e os dados de tempo de treinamento s√£o cruzados para esses modelos selecionados, preparando os resultados para visualiza√ß√£o futura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98028951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèÜ Verifica√ß√£o e atualiza√ß√£o dos 5 melhores modelos\n",
    "\n",
    "caminho_csv = 'melhores_modelos.csv'\n",
    "if os.path.exists(caminho_csv):\n",
    "    melhores_anteriores = pd.read_csv(caminho_csv)\n",
    "    combinados = pd.concat([melhores_anteriores, atual_resultados], ignore_index=True)\n",
    "    combinados = combinados.sort_values(by='F1 Score', ascending=False).drop_duplicates('Modelo').head(5)\n",
    "else:\n",
    "    combinados = atual_resultados.head(5)\n",
    "\n",
    "# Salvar top 5 atualizados\n",
    "combinados.to_csv(caminho_csv, index=False)\n",
    "\n",
    "# 3. Cria a pasta para salvar os modelos (se n√£o existir)\n",
    "os.makedirs(\"modelos_salvos\", exist_ok=True)\n",
    "\n",
    "# 4. Salva somente os modelos que est√£o no top 5\n",
    "modelos_treinados = {}\n",
    "y_preds = {}\n",
    "tempos = []\n",
    "\n",
    "# Cria um set com os nomes dos top 5 para facilitar a verifica√ß√£o\n",
    "top5_modelos = set(combinados['Modelo'])\n",
    "\n",
    "for nome, modelo in modelos:\n",
    "    if nome in top5_modelos:\n",
    "        nome_arquivo = f\"modelos_salvos/{nome.replace(' ', '_')}.pkl\"\n",
    "        joblib.dump(modelo, nome_arquivo)\n",
    "        print(f\"Modelo salvo em: {nome_arquivo}\")\n",
    "\n",
    "        modelos_treinados[nome] = modelo\n",
    "        y_preds[nome] = y_pred  # Supondo que y_pred esteja atualizado para esse modelo\n",
    "        tempos.append({'Modelo': nome, 'Tempo Treinamento (s)': round(duracao, 3)})\n",
    "\n",
    "# Gerar top 5 resultados e tempos atualizados\n",
    "top5_resultados = combinados \n",
    "top5_tempos = df_tempos.merge(top5_resultados[['Modelo']], on='Modelo')\n",
    "top5_tempos['Modelo'] = pd.Categorical(top5_tempos['Modelo'], categories=top5_resultados['Modelo'], ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63bac3",
   "metadata": {},
   "source": [
    "üìä Visualiza√ß√£o dos 5 melhores modelos\n",
    "\n",
    "Esta c√©lula gera gr√°ficos para comparar visualmente o desempenho dos 5 melhores modelos selecionados. S√£o exibidos:\n",
    "\n",
    "- Um gr√°fico de barras do F1 Score para os top 5 modelos, facilitando a compara√ß√£o direta de desempenho.\n",
    "- Um heatmap com todas as m√©tricas de avalia√ß√£o para esses modelos, mostrando detalhes de performance de forma clara.\n",
    "- Um gr√°fico de barras com o tempo de treinamento de cada modelo, para analisar o custo computacional associado a cada um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìä Visualiza√ß√£o dos 5 melhores modelos\n",
    "\n",
    "# F1 Score dos top 5 modelos\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=top5_resultados, x='F1 Score', y='Modelo', hue='Modelo', palette='viridis', legend=False)\n",
    "plt.title('F1 Score - Top 5 Modelos')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heatmap dos top 5 modelos\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(top5_resultados.drop(columns='Modelo').set_index(top5_resultados['Modelo']).astype(float),annot=True,cmap='YlGnBu',fmt='.2f')\n",
    "plt.title('üìä Heatmap - Top 5 Modelos')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gr√°fico de tempo dos top 5 modelos\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=top5_tempos, x='Tempo Treinamento (s)', y='Modelo', hue='Modelo', palette='magma', legend=False)\n",
    "plt.title('‚è±Ô∏è Tempo de Treinamento - Top 5 Modelos')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec6358f",
   "metadata": {},
   "source": [
    "üìë Apresenta√ß√£o detalhada de m√©tricas preditivas para cada algoritmo\n",
    "\n",
    "Esta c√©lula imprime, para cada modelo testado:\n",
    "\n",
    "- A acur√°cia m√©dia da valida√ß√£o cruzada, que fornece uma estimativa mais robusta do desempenho geral, suavizando varia√ß√µes entre divis√µes dos dados;\n",
    "- O relat√≥rio de classifica√ß√£o (classification_report), que mostra m√©tricas espec√≠ficas por classe (precis√£o, recall, f1-score), possibilitando uma avalia√ß√£o mais granular da performance;\n",
    "- A matriz de confus√£o, que evidencia os acertos e erros de classifica√ß√£o por categoria, sendo crucial para entender onde os modelos est√£o confundindo as culturas agr√≠colas.\n",
    "\n",
    "Essa an√°lise detalhada √© essencial para identificar n√£o apenas qual modelo tem melhor desempenho geral, mas tamb√©m quais est√£o mais equilibrados entre as classes e quais podem estar cometendo erros sistem√°ticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìë Apresenta√ß√£o detalhada de m√©tricas preditivas para cada algoritmo\n",
    "\n",
    "for nome in top5_resultados['Modelo']:\n",
    "    print(f\"\\nüîç Avaliando modelo: {nome}\")\n",
    "\n",
    "    # Tenta obter o modelo: da mem√≥ria ou do disco\n",
    "    if nome in modelos_treinados:\n",
    "        modelo = modelos_treinados[nome]\n",
    "    else:\n",
    "        try:\n",
    "            caminho_modelo = f\"modelos_salvos/{nome}.pkl\"\n",
    "            modelo = joblib.load(caminho_modelo)\n",
    "            print(f\"üìÇ Modelo '{nome}' carregado do disco com sucesso.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå Modelo '{nome}' n√£o foi treinado nesta execu√ß√£o e tamb√©m n√£o foi encontrado em disco.\")\n",
    "            continue  # neste caso, n√£o tem como avaliar\n",
    "\n",
    "    # Tenta obter as previs√µes\n",
    "    if nome in y_preds:\n",
    "        y_pred = y_preds[nome]\n",
    "    else:\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        y_preds[nome] = y_pred  # salva para reutiliza√ß√£o, se necess√°rio\n",
    "        \n",
    "        \n",
    "    # Avalia√ß√£o\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"‚úÖ Acur√°cia: {acc:.4f}\")\n",
    "    print(f\"‚úÖ Precis√£o: {prec:.4f}\")\n",
    "    print(f\"‚úÖ Revoca√ß√£o: {rec:.4f}\")\n",
    "    print(f\"‚úÖ F1-Score: {f1:.4f}\")\n",
    "\n",
    "    # Relat√≥rio de classifica√ß√£o\n",
    "    print(\"\\nüìÑ Relat√≥rio de Classifica√ß√£o:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))\n",
    "\n",
    "    # Matriz de confus√£o\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f\"Matriz de Confus√£o - {nome}\")\n",
    "    plt.xlabel(\"Previsto\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc38cc",
   "metadata": {},
   "source": [
    "üìà Visualiza√ß√£o da distribui√ß√£o das classes no conjunto de teste\n",
    "\n",
    "Por fim, esta c√©lula gera um gr√°fico de barras mostrando a quantidade de amostras por classe no conjunto de teste. Essa an√°lise ajuda a verificar o balanceamento das classes, fundamental para interpretar corretamente as m√©tricas dos modelos e evitar vi√©s em classifica√ß√µes desbalanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eeba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üìà Visualiza√ß√£o da distribui√ß√£o das classes no conjunto de teste\n",
    "\n",
    "pd.DataFrame(le.inverse_transform(y_test)) \\\n",
    "    .value_counts() \\\n",
    "    .reset_index(name='count') \\\n",
    "    .rename(columns={'index': 'label'}) \\\n",
    "    .sort_values(by='count', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
